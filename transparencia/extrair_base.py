#!/usr/bin/env python3
"""
ObservatÃ³rio de Integridade â€” ExtraÃ§Ã£o Portal BASE v3
========================================================

Usa o Portal da TransparÃªncia do SNS (transparencia.sns.gov.pt)
que disponibiliza os MESMOS dados do Portal BASE numa interface
de dados abertos que funciona sem ficheiros com carimbos temporais.

Fonte alternativa: dados.gov.pt (descarregamento manual)

Uso:
  pip install pandas requests
  python extrair_base.py
"""

import sys
import json
from pathlib import Path
from datetime import datetime

try:
    import pandas as pd
    import requests
except ImportError:
    print("Instala: pip install pandas requests")
    sys.exit(1)

DIR = Path("dados_base")
DIR.mkdir(exist_ok=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FONTES DE DADOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# API OpenDataSoft do Portal da TransparÃªncia SNS
# Conjunto: portal-base (contratos pÃºblicos â€” mesmos dados do BASE)
# DocumentaÃ§Ã£o: https://transparencia.sns.gov.pt/explore/dataset/portal-base/api/
SNS_BASE = "https://transparencia.sns.gov.pt"
SNS_DATASET = "portal-base"

# ExportaÃ§Ã£o directa em CSV (atÃ© 10.000 registos por pedido)
SNS_EXPORT = f"{SNS_BASE}/api/explore/v2.1/catalog/datasets/{SNS_DATASET}/exports/csv"

# Consulta de registos (paginada, sem limite)
SNS_RECORDS = f"{SNS_BASE}/api/explore/v2.1/catalog/datasets/{SNS_DATASET}/records"

# LigaÃ§Ã£o directa para descarregamento completo (sem limite de registos)
SNS_COMPLETO = f"{SNS_BASE}/explore/dataset/{SNS_DATASET}/download/?format=csv&timezone=Europe/Lisbon"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. DESCARREGAMENTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def contar_registos():
    """Consulta quantos registos existem no conjunto de dados."""
    try:
        r = requests.get(SNS_RECORDS, params={"limit": 0}, timeout=30)
        r.raise_for_status()
        total = r.json().get("total_count", 0)
        return total
    except Exception as e:
        print(f"  âš  Erro ao consultar API: {e}")
        return 0


def descarregar_via_export(path, limit=10000):
    """Descarrega via interface de exportaÃ§Ã£o (rÃ¡pido, atÃ© 10 mil registos)."""
    print(f"  â†“ A descarregar via exportaÃ§Ã£o (limite: {limit})...")
    params = {
        "delimiter": ";",
        "list_separator": "|",
        "limit": limit,
        "offset": 0,
    }
    try:
        r = requests.get(SNS_EXPORT, params=params, timeout=120)
        r.raise_for_status()
        with open(path, "wb") as f:
            f.write(r.content)
        print(f"  âœ“ {path.name} ({path.stat().st_size / 1e6:.1f} MB)")
        return True
    except Exception as e:
        print(f"  âœ— {e}")
        return False


def descarregar_completo(path):
    """Descarrega o CSV completo via ligaÃ§Ã£o directa."""
    print(f"  â†“ A descarregar CSV completo...")
    try:
        r = requests.get(SNS_COMPLETO, timeout=300, stream=True)
        r.raise_for_status()
        total = int(r.headers.get("content-length", 0))
        recebido = 0
        with open(path, "wb") as f:
            for pedaÃ§o in r.iter_content(65536):
                f.write(pedaÃ§o)
                recebido += len(pedaÃ§o)
                if total:
                    print(f"\r    {recebido/1e6:.1f}/{total/1e6:.1f} MB", end="", flush=True)
        print()
        if path.stat().st_size > 100:
            print(f"  âœ“ {path.name} ({path.stat().st_size / 1e6:.1f} MB)")
            return True
    except Exception as e:
        print(f"  âœ— {e}")
    return False


def descarregar_paginado(path, lote=100):
    """Descarrega por pÃ¡ginas (mais lento, mas fiÃ¡vel)."""
    print(f"  â†“ A descarregar por pÃ¡ginas (lotes de {lote})...")
    registos = []
    offset = 0
    total = contar_registos()
    if total == 0:
        print("  âœ— Sem registos")
        return False
    
    print(f"    Total: {total:,} registos")
    
    while offset < total:
        try:
            r = requests.get(SNS_RECORDS, params={
                "limit": lote,
                "offset": offset,
            }, timeout=60)
            r.raise_for_status()
            dados = r.json()
            resultados = dados.get("results", [])
            if not resultados:
                break
            for reg in resultados:
                registos.append(reg.get("record", {}).get("fields", reg))
            offset += lote
            print(f"\r    {len(registos):,} / {total:,}", end="", flush=True)
        except Exception as e:
            print(f"\n  âš  Erro na posiÃ§Ã£o {offset}: {e}")
            break
    
    print()
    if registos:
        df = pd.DataFrame(registos)
        df.to_csv(path, index=False, encoding="utf-8-sig", sep=";")
        print(f"  âœ“ {path.name} ({len(registos):,} registos)")
        return True
    return False


def obter_dados():
    """Tenta vÃ¡rias formas de obter os dados."""
    print("\nâ•â•â• FASE 1: DESCARREGAMENTO â•â•â•\n")
    
    # Verificar ficheiro local
    for f in DIR.glob("*.csv"):
        if f.stat().st_size > 1000:
            print(f"  âœ“ Ficheiro local encontrado: {f.name} ({f.stat().st_size/1e6:.1f} MB)")
            return f
    for f in DIR.glob("*.xlsx"):
        if f.stat().st_size > 1000:
            print(f"  âœ“ Ficheiro local encontrado: {f.name} ({f.stat().st_size/1e6:.1f} MB)")
            return f
    
    path = DIR / "portal_base.csv"
    
    # Contar registos
    total = contar_registos()
    if total > 0:
        print(f"  ğŸ“Š {total:,} registos disponÃ­veis na API")
    
    # Tentativa 1: Descarregamento completo
    if descarregar_completo(path):
        return path
    
    # Tentativa 2: ExportaÃ§Ã£o por lotes
    if descarregar_via_export(path, limit=min(total, 10000)):
        return path
    
    # Tentativa 3: Consulta por pÃ¡ginas
    if total > 0:
        if descarregar_paginado(path):
            return path
    
    print("\n  âœ— NÃ£o foi possÃ­vel descarregar os dados.")
    print("  Alternativas:")
    print(f"  1. Abre: {SNS_BASE}/explore/dataset/{SNS_DATASET}/export/?sort=datacelebracaocontrato")
    print(f"     Descarrega o CSV e coloca na pasta {DIR}/")
    print(f"  2. Abre: https://dados.gov.pt/en/datasets/contratos-publicos-portal-base-impic-contratos-de-2012-a-2026/")
    print(f"     Descarrega qualquer ficheiro xlsx e coloca na pasta {DIR}/")
    return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. CARREGAMENTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def carregar(path):
    """Carrega CSV ou XLSX."""
    print(f"\n  ğŸ“„ A ler {path.name}...")
    
    if path.suffix == ".xlsx":
        try:
            import openpyxl
        except ImportError:
            print("  Instala: pip install openpyxl")
            sys.exit(1)
        df = pd.read_excel(path, engine="openpyxl")
    elif path.suffix == ".csv":
        for sep in [";", ",", "\t"]:
            for enc in ["utf-8-sig", "utf-8", "latin-1", "cp1252"]:
                try:
                    df = pd.read_csv(path, sep=sep, encoding=enc, low_memory=False)
                    if len(df.columns) > 3:
                        break
                except:
                    continue
            else:
                continue
            break
        else:
            print("  âœ— NÃ£o consegui ler o CSV"); return None
    else:
        print(f"  âœ— Formato nÃ£o suportado: {path.suffix}"); return None
    
    print(f"  â†’ {len(df):,} registos, {len(df.columns)} colunas")
    print(f"  â†’ Colunas: {list(df.columns)}")
    return df


def normalizar(df):
    """Normaliza nomes de colunas â€” suporta tanto dados.gov.pt como transparencia.sns.gov.pt."""
    
    # Mapeamento: nome interno â†’ lista de variantes possÃ­veis nas fontes
    correspondencias = {
        "nipc_adjudicatario": [
            "nifs_das_adjudicatarias",          # transparencia.sns.gov.pt
            "nifadjudicatario",                  # dados.gov.pt
            "adjudicatarionif", "adjudicatario_nif",
        ],
        "nome_adjudicatario": [
            "entidades_adjudicatarias_normalizado",  # transparencia.sns.gov.pt
            "nomeadjudicatario",                      # dados.gov.pt
            "adjudicatariodesignacao", "adjudicatario_designacao",
        ],
        "nipc_adjudicante": [
            "nifs_dos_adjudicantes",             # transparencia.sns.gov.pt
            "nifadjudicante",                    # dados.gov.pt
            "adjudicantenif", "adjudicante_nif",
        ],
        "nome_adjudicante": [
            "entidades_adjudicantes_normalizado",  # transparencia.sns.gov.pt
            "nomeadjudicante",                      # dados.gov.pt
            "adjudicantedesignacao", "adjudicante_designacao",
        ],
        "preco": [
            "preco_contratual",                  # transparencia.sns.gov.pt
            "precocontratual",                   # dados.gov.pt
            "precoefetivo",
        ],
        "tipo_procedimento": [
            "tipo_de_procedimento",              # transparencia.sns.gov.pt
            "tipoprocedimento",                  # dados.gov.pt
            "tipodeprocedimento",
        ],
        "data_celebracao": [
            "data_de_celebracao_do_contrato",    # transparencia.sns.gov.pt
            "datacelebracaocontrato",            # dados.gov.pt
            "datacelebracao", "data_celebracao",
        ],
        "objeto": [
            "objeto_do_contrato",                # transparencia.sns.gov.pt
            "objectocontrato",                   # dados.gov.pt
            "objetocontrato",
        ],
        "tipo_contrato": [
            "tipos_de_contrato",                 # transparencia.sns.gov.pt
            "tipocontrato",                      # dados.gov.pt
        ],
        "local_execucao": [
            "local_de_execucao",                 # transparencia.sns.gov.pt
        ],
        "preco_efetivo": [
            "preco_total_efetivo",               # transparencia.sns.gov.pt
        ],
    }
    
    # Criar Ã­ndice das colunas reais (sem espaÃ§os, sublinhados, hÃ­fenes)
    indice = {}
    for c in df.columns:
        chave = c.lower().strip().replace(" ","").replace("-","")
        indice[chave] = c
        # TambÃ©m sem sublinhados para apanhar variantes
        chave2 = chave.replace("_","")
        indice[chave2] = c
    
    renomear = {}
    for alvo, candidatos in correspondencias.items():
        for cand in candidatos:
            # Tentar com sublinhados
            if cand in [c.lower() for c in df.columns]:
                col_real = [c for c in df.columns if c.lower() == cand][0]
                renomear[col_real] = alvo
                break
            # Tentar sem sublinhados
            limpo = cand.lower().replace("_","")
            if limpo in indice:
                renomear[indice[limpo]] = alvo
                break
    
    if renomear:
        df = df.rename(columns=renomear)
        print(f"  â†’ Colunas normalizadas: {list(renomear.values())}")
    
    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ANÃLISES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analise_fragmentacao(df, limiar=20000, minimo=5):
    """Detecta fragmentaÃ§Ã£o: ajustes directos repetidos abaixo do limiar legal."""
    print("\nğŸ” FRAGMENTAÃ‡ÃƒO DE CONTRATOS")
    print(f"   Ajustes directos repetidos abaixo de â‚¬{limiar:,}")
    print("â”€" * 55)
    
    if "preco" not in df.columns:
        print("  âš  Sem coluna de preÃ§o"); return
    
    t = df.copy()
    t["_p"] = pd.to_numeric(t["preco"], errors="coerce")
    
    if "tipo_procedimento" in t.columns:
        t = t[t["tipo_procedimento"].str.contains("direto|directo|simplif", case=False, na=False)]
    
    t = t[t["_p"] < limiar]
    
    colunas = [c for c in ["nome_adjudicante","nome_adjudicatario","nipc_adjudicatario"] if c in t.columns]
    if not colunas:
        print("  âš  Sem colunas de agrupamento"); return
    
    a = t.groupby(colunas).agg(
        n=("_p","count"), total=("_p","sum"), media=("_p","mean"),
        mn=("_p","min"), mx=("_p","max")
    ).reset_index()
    
    s = a[a["n"] >= minimo].sort_values("total", ascending=False)
    
    print(f"\n  âš  {len(s)} pares suspeitos (â‰¥{minimo} ajustes directos <â‚¬{limiar:,})\n")
    for _, r in s.head(15).iterrows():
        print(f"  â”Œ {r.get('nome_adjudicatario','?')}")
        nipc = r.get('nipc_adjudicatario','')
        if nipc:
            print(f"  â”‚ NIPC: {nipc}")
        print(f"  â”‚ â† {r.get('nome_adjudicante','?')}")
        print(f"  â”‚ {r['n']} contratos  â‚¬{r['total']:,.0f} (mÃ©dia â‚¬{r['media']:,.0f})")
        if r["mx"] < limiar and r["mn"] > limiar * 0.6:
            print(f"  â”‚ ğŸš© Valores sistematicamente junto ao limiar!")
        print(f"  â””{'â”€'*53}\n")


def analise_temporal(df):
    """Detecta concentraÃ§Ã£o temporal anÃ³mala."""
    print("\nğŸ” CONCENTRAÃ‡ÃƒO TEMPORAL")
    print("â”€" * 55)
    
    if "data_celebracao" not in df.columns:
        print("  âš  Sem coluna de data"); return
    
    t = df.copy()
    t["_d"] = pd.to_datetime(t["data_celebracao"], errors="coerce")
    t["_m"] = t["_d"].dt.month
    
    meses = ["Jan","Fev","Mar","Abr","Mai","Jun","Jul","Ago","Set","Out","Nov","Dez"]
    pm = t.dropna(subset=["_m"]).groupby("_m").size()
    media = pm.mean()
    
    print(f"\n  MÃ©dia: {media:.0f} contratos/mÃªs\n")
    for m in range(1,13):
        n = pm.get(m,0)
        p = n/media*100 if media else 0
        print(f"    {meses[m-1]}: {n:>6,}  ({p:>5.0f}%) {'â–ˆ'*int(p/8)}{'  âš  PICO' if p>150 else ''}")


def analise_dominante(df, quota_min=25):
    """Detecta fornecedores dominantes numa entidade."""
    print(f"\nğŸ” FORNECEDORES DOMINANTES (>{quota_min}%)")
    print("â”€" * 55)
    
    if "preco" not in df.columns: return
    t = df.copy()
    t["_p"] = pd.to_numeric(t["preco"], errors="coerce")
    
    ca = "nome_adjudicante"
    cf = "nome_adjudicatario"
    if ca not in t.columns or cf not in t.columns: return
    
    te = t.groupby(ca)["_p"].sum().reset_index(name="te")
    pa = t.groupby([ca,cf]).agg(n=("_p","count"), total=("_p","sum")).reset_index()
    m = pa.merge(te, on=ca)
    m["quota"] = (m["total"]/m["te"]*100).round(1)
    
    s = m[m["quota"] >= quota_min].sort_values("quota", ascending=False)
    print(f"\n  âš  {len(s)} pares com fornecedor dominante\n")
    for _,r in s.head(10).iterrows():
        print(f"  {r[cf][:50]}")
        print(f"    â†’ {r[ca][:50]}  {r['quota']}%  â‚¬{r['total']:,.0f} ({r['n']} contratos)\n")


def analise_top(df, n=20):
    """Maiores adjudicatÃ¡rios por valor total."""
    print(f"\nğŸ” MAIORES ADJUDICATÃRIOS (TOP {n})")
    print("â”€" * 55)
    
    if "preco" not in df.columns: return
    t = df.copy()
    t["_p"] = pd.to_numeric(t["preco"], errors="coerce")
    
    cf = "nome_adjudicatario"
    if cf not in t.columns: return
    
    a = t.groupby(cf).agg(n=("_p","count"), total=("_p","sum")).reset_index()
    a = a.sort_values("total", ascending=False)
    
    print()
    for i, (_, r) in enumerate(a.head(n).iterrows(), 1):
        print(f"  {i:>2}. {r[cf][:55]:<57} {r['n']:>5} contratos  â‚¬{r['total']:>14,.2f}")


def resumo(df):
    """Resumo do conjunto de dados."""
    print(f"\nğŸ“Š RESUMO")
    print("â”€" * 55)
    print(f"  Registos:  {len(df):,}")
    if "preco" in df.columns:
        v = pd.to_numeric(df["preco"], errors="coerce")
        print(f"  Valor total: â‚¬{v.sum():,.2f}")
        print(f"  Mediana:     â‚¬{v.median():,.2f}")
    if "tipo_procedimento" in df.columns:
        print(f"\n  Procedimentos:")
        for proc, n in df["tipo_procedimento"].value_counts().head(8).items():
            print(f"    {proc:<50} {n:>6,}")
    if "data_celebracao" in df.columns:
        d = pd.to_datetime(df["data_celebracao"], errors="coerce")
        print(f"\n  PerÃ­odo: {d.min()} â€” {d.max()}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  OBSERVATÃ“RIO DE INTEGRIDADE â€” PORTUGAL             â•‘
â•‘  ExtraÃ§Ã£o Portal BASE v3                            â•‘
â•‘                                                      â•‘
â•‘  Fonte: transparencia.sns.gov.pt (Portal BASE)      â•‘
â•‘  LicenÃ§a: Dados abertos â€” DomÃ­nio PÃºblico           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    caminho = obter_dados()
    
    if caminho is None:
        sys.exit(1)
    
    print("\nâ•â•â• FASE 2: CARREGAMENTO â•â•â•")
    df = carregar(caminho)
    if df is None:
        sys.exit(1)
    
    df = normalizar(df)
    resumo(df)
    
    print("\nâ•â•â• FASE 3: ANÃLISE â•â•â•")
    analise_fragmentacao(df)
    analise_temporal(df)
    analise_dominante(df)
    analise_top(df)
    
    # Exportar resultado limpo
    saida = DIR / "resultado.csv"
    df.to_csv(saida, index=False, encoding="utf-8-sig")
    print(f"\n  âœ“ Exportado: {saida}")
    
    print(f"""
{'â•'*55}
  ConcluÃ­do. {len(df):,} contratos analisados.
  
  PrÃ³ximos passos:
  Â· Cruzar NIPC com Registo Comercial (sÃ³cios/gerentes)
  Â· Cruzar nomes com listas de autarcas e deputados
  Â· Cruzar com doaÃ§Ãµes a partidos (ECFP/CNE)
{'â•'*55}
    """)


if __name__ == "__main__":
    main()